{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69a03ac-a09f-46ce-bed6-04f87d622156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,\n",
       " 200,\n",
       " count    1600.000000\n",
       " mean      230.710000\n",
       " std       170.682582\n",
       " min        16.000000\n",
       " 25%       127.000000\n",
       " 50%       175.000000\n",
       " 75%       283.250000\n",
       " max      1300.000000\n",
       " Name: Review, dtype: float64,\n",
       " count    200.00000\n",
       " mean     235.79000\n",
       " std      172.64905\n",
       " min       36.00000\n",
       " 25%      130.75000\n",
       " 50%      178.50000\n",
       " 75%      289.00000\n",
       " max      977.00000\n",
       " Name: Review, dtype: float64,\n",
       " 47638,\n",
       " 11709,\n",
       " 7245)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "\n",
    "# 读取训练集和验证集文件\n",
    "train_file = 'movie_reviews_train.txt'\n",
    "dev_file = 'movie_reviews_dev.txt'\n",
    "\n",
    "# 读取数据\n",
    "train_data = pd.read_csv(train_file, sep='\\t', header=None, names=[\"ID\", \"Review\", \"Label\"])\n",
    "dev_data = pd.read_csv(dev_file, sep='\\t', header=None, names=[\"ID\", \"Review\", \"Label\"])\n",
    "\n",
    "# 计算训练集和验证集的评论数和每条评论的词汇数\n",
    "train_num_reviews = len(train_data)\n",
    "dev_num_reviews = len(dev_data)\n",
    "\n",
    "# 计算每条评论的词汇数\n",
    "train_token_counts = train_data['Review'].apply(lambda x: len(x.split()))\n",
    "dev_token_counts = dev_data['Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# 计算训练集和验证集的词汇数量\n",
    "train_vocab_size = len(set(\" \".join(train_data['Review']).split()))\n",
    "dev_vocab_size = len(set(\" \".join(dev_data['Review']).split()))\n",
    "\n",
    "# 计算训练集和验证集的词汇表重叠\n",
    "train_vocab = set(\" \".join(train_data['Review']).split())\n",
    "dev_vocab = set(\" \".join(dev_data['Review']).split())\n",
    "vocab_overlap = len(train_vocab.intersection(dev_vocab))\n",
    "\n",
    "# 输出结果\n",
    "train_num_reviews, dev_num_reviews, train_token_counts.describe(), dev_token_counts.describe(), train_vocab_size, dev_vocab_size, vocab_overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3016e88a-910b-4ece-bd5f-934f8d905109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47638, 11709)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新计算独立词汇数量\n",
    "train_vocab_unique = set(\" \".join(train_data['Review']).split())\n",
    "dev_vocab_unique = set(\" \".join(dev_data['Review']).split())\n",
    "\n",
    "# 输出训练集和验证集的独立词汇表大小\n",
    "len(train_vocab_unique), len(dev_vocab_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064edd4e-c717-4ec8-ad4f-c0e4574112b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/huangjiabao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/huangjiabao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d5d78e-b3ce-4e32-bdd8-2aaad7dcd0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/huangjiabao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表重叠的大小: 6132\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# 下载punkt分词模型（如果尚未下载）\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# 读取并分词的函数\n",
    "def load_and_tokenize(file_path):\n",
    "    with open(file_path, 'r', encoding='utf8') as file:\n",
    "        reviews = file.readlines()\n",
    "    # 提取评论文本（去除电影ID和评分）\n",
    "    reviews_text = [line.split(\"\\t\")[1] for line in reviews if len(line.strip()) > 0]\n",
    "    # 分词\n",
    "    tokenized_reviews = [word_tokenize(review.lower()) for review in reviews_text]\n",
    "    return tokenized_reviews\n",
    "\n",
    "# 读取并分词训练集和验证集的评论\n",
    "train_file_path = 'movie_reviews_train.txt'  # 修改为您训练集的文件路径\n",
    "dev_file_path = 'movie_reviews_dev.txt'      # 修改为您验证集的文件路径\n",
    "\n",
    "train_reviews = load_and_tokenize(train_file_path)\n",
    "dev_reviews = load_and_tokenize(dev_file_path)\n",
    "\n",
    "# 获取训练集和验证集的词汇表（唯一词汇）\n",
    "train_vocab = set([word for review in train_reviews for word in review])\n",
    "dev_vocab = set([word for review in dev_reviews for word in review])\n",
    "\n",
    "# 计算训练集和验证集词汇表之间的重叠\n",
    "overlap_vocab = train_vocab.intersection(dev_vocab)\n",
    "overlap_size = len(overlap_vocab)\n",
    "\n",
    "# 输出词汇重叠的大小\n",
    "print(f\"词汇表重叠的大小: {overlap_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652b479b-78cc-427e-89c1-2232a3ec912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/huangjiabao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/huangjiabao/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集词汇表重叠百分比: 22.57%\n",
      "验证集词汇表重叠百分比: 75.17%\n"
     ]
    }
   ],
   "source": [
    "# # 改进代码，实现百分比：\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # 下载punkt分词模型（如果尚未下载）\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# # 读取并分词的函数\n",
    "# def load_and_tokenize(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf8') as file:\n",
    "#         reviews = file.readlines()\n",
    "#     # 提取评论文本（去除电影ID和评分）\n",
    "#     reviews_text = [line.split(\"\\t\")[1] for line in reviews if len(line.strip()) > 0]\n",
    "#     # 分词\n",
    "#     tokenized_reviews = [word_tokenize(review.lower()) for review in reviews_text]\n",
    "#     return tokenized_reviews\n",
    "\n",
    "# # 读取并分词训练集和验证集的评论\n",
    "# train_file_path = 'movie_reviews_train.txt'  # 修改为您训练集的文件路径\n",
    "# dev_file_path = 'movie_reviews_dev.txt'      # 修改为您验证集的文件路径\n",
    "\n",
    "# train_reviews = load_and_tokenize(train_file_path)\n",
    "# dev_reviews = load_and_tokenize(dev_file_path)\n",
    "\n",
    "# # 获取训练集和验证集的词汇表（唯一词汇）\n",
    "# train_vocab = set([word for review in train_reviews for word in review])\n",
    "# dev_vocab = set([word for review in dev_reviews for word in review])\n",
    "\n",
    "# # 计算训练集和验证集词汇表之间的重叠\n",
    "# overlap_vocab = train_vocab.intersection(dev_vocab)\n",
    "# overlap_size = len(overlap_vocab)\n",
    "\n",
    "# # 计算重叠词汇的百分比\n",
    "# train_vocab_size = len(train_vocab)\n",
    "# dev_vocab_size = len(dev_vocab)\n",
    "\n",
    "# # 计算重叠词汇的百分比\n",
    "# overlap_percentage_train = (overlap_size / train_vocab_size) * 100\n",
    "# overlap_percentage_dev = (overlap_size / dev_vocab_size) * 100\n",
    "\n",
    "# # 输出百分比结果\n",
    "# print(f\"训练集词汇表重叠百分比: {overlap_percentage_train:.2f}%\")\n",
    "# print(f\"验证集词汇表重叠百分比: {overlap_percentage_dev:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4055c923-4ad6-4e26-994f-954003b95628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集和验证集词汇表重叠的大小: 6132\n"
     ]
    }
   ],
   "source": [
    "# 计算词汇重叠的大小\n",
    "overlap_size = len(overlap_vocab)\n",
    "\n",
    "# 输出重叠的大小\n",
    "print(f\"训练集和验证集词汇表重叠的大小: {overlap_size}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
